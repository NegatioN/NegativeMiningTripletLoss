{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses\n",
    "> Where all of the losses are situated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "def _pairwise_distances(embeddings, squared=False):\n",
    "    \"\"\"Compute the 2D matrix of distances between all the embeddings.\n",
    "\n",
    "    Args:\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        pairwise_distances: tensor of shape (batch_size, batch_size)\n",
    "    \"\"\"\n",
    "    dot_product = torch.matmul(embeddings, embeddings.t())\n",
    "\n",
    "    # Get squared L2 norm for each embedding. We can just take the diagonal of `dot_product`.\n",
    "    # This also provides more numerical stability (the diagonal of the result will be exactly 0).\n",
    "    # shape (batch_size,)\n",
    "    square_norm = torch.diag(dot_product)\n",
    "\n",
    "    # Compute the pairwise distance matrix as we have:\n",
    "    # ||a - b||^2 = ||a||^2  - 2 <a, b> + ||b||^2\n",
    "    # shape (batch_size, batch_size)\n",
    "    distances = square_norm.unsqueeze(0) - 2.0 * dot_product + square_norm.unsqueeze(1)\n",
    "\n",
    "    # Because of computation errors, some distances might be negative so we put everything >= 0.0\n",
    "    distances[distances < 0] = 0\n",
    "\n",
    "    if not squared:\n",
    "        # Because the gradient of sqrt is infinite when distances == 0.0 (ex: on the diagonal)\n",
    "        # we need to add a small epsilon where distances == 0.0\n",
    "        mask = distances.eq(0).float()\n",
    "        distances = distances + mask * 1e-16\n",
    "\n",
    "        distances = (1.0 -mask) * torch.sqrt(distances)\n",
    "\n",
    "    return distances\n",
    "\n",
    "def _get_triplet_mask(labels):\n",
    "    \"\"\"Return a 3D mask where mask[a, p, n] is True iff the triplet (a, p, n) is valid.\n",
    "    A triplet (i, j, k) is valid if:\n",
    "        - i, j, k are distinct\n",
    "        - labels[i] == labels[j] and labels[i] != labels[k]\n",
    "    Args:\n",
    "        labels: tf.int32 `Tensor` with shape [batch_size]\n",
    "    \"\"\"\n",
    "    # Check that i, j and k are distinct\n",
    "    indices_equal = torch.eye(labels.size(0), device=labels.device).bool()\n",
    "    indices_not_equal = ~indices_equal\n",
    "    i_not_equal_j = indices_not_equal.unsqueeze(2)\n",
    "    i_not_equal_k = indices_not_equal.unsqueeze(1)\n",
    "    j_not_equal_k = indices_not_equal.unsqueeze(0)\n",
    "\n",
    "    distinct_indices = (i_not_equal_j & i_not_equal_k) & j_not_equal_k\n",
    "\n",
    "\n",
    "    label_equal = labels.unsqueeze(0) == labels.unsqueeze(1)\n",
    "    i_equal_j = label_equal.unsqueeze(2)\n",
    "    i_equal_k = label_equal.unsqueeze(1)\n",
    "\n",
    "    valid_labels = ~i_equal_k & i_equal_j\n",
    "\n",
    "    return valid_labels & distinct_indices\n",
    "\n",
    "\n",
    "def _get_anchor_positive_triplet_mask(labels):\n",
    "    \"\"\"Return a 2D mask where mask[a, p] is True iff a and p are distinct and have same label.\n",
    "    Args:\n",
    "        labels: tf.int32 `Tensor` with shape [batch_size]\n",
    "    Returns:\n",
    "        mask: tf.bool `Tensor` with shape [batch_size, batch_size]\n",
    "    \"\"\"\n",
    "    # Check that i and j are distinct\n",
    "    indices_equal = torch.eye(labels.size(0), device=labels.device).bool()\n",
    "    indices_not_equal = ~indices_equal\n",
    "\n",
    "    # Check if labels[i] == labels[j]\n",
    "    # Uses broadcasting where the 1st argument has shape (1, batch_size) and the 2nd (batch_size, 1)\n",
    "    labels_equal = labels.unsqueeze(0) == labels.unsqueeze(1)\n",
    "\n",
    "    return labels_equal & indices_not_equal\n",
    "\n",
    "\n",
    "def _get_anchor_negative_triplet_mask(labels):\n",
    "    \"\"\"Return a 2D mask where mask[a, n] is True iff a and n have distinct labels.\n",
    "    Args:\n",
    "        labels: tf.int32 `Tensor` with shape [batch_size]\n",
    "    Returns:\n",
    "        mask: tf.bool `Tensor` with shape [batch_size, batch_size]\n",
    "    \"\"\"\n",
    "    # Check if labels[i] != labels[k]\n",
    "    # Uses broadcasting where the 1st argument has shape (1, batch_size) and the 2nd (batch_size, 1)\n",
    "\n",
    "    return ~(labels.unsqueeze(0) == labels.unsqueeze(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import numpy as np\n",
    "\n",
    "# Test-suite from https://github.com/omoindrot/tensorflow-triplet-loss/blob/master/model/tests/test_triplet_loss.py\n",
    "# Skipped the `test_gradients_pairwise_distances()` test since it's trivial to see if your model loss turns NaN\n",
    "# and porting it proved more difficult than expected.\n",
    "\n",
    "def pairwise_distance_np(feature, squared=False):\n",
    "    \"\"\"Computes the pairwise distance matrix in numpy.\n",
    "    Args:\n",
    "        feature: 2-D numpy array of size [number of data, feature dimension]\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean\n",
    "                 distance matrix; else, output is the pairwise euclidean distance matrix.\n",
    "    Returns:\n",
    "        pairwise_distances: 2-D numpy array of size\n",
    "                            [number of data, number of data].\n",
    "    \"\"\"\n",
    "    triu = np.triu_indices(feature.shape[0], 1)\n",
    "    upper_tri_pdists = np.linalg.norm(feature[triu[1]] - feature[triu[0]], axis=1)\n",
    "    if squared:\n",
    "        upper_tri_pdists **= 2.\n",
    "    num_data = feature.shape[0]\n",
    "    pairwise_distances = np.zeros((num_data, num_data))\n",
    "    pairwise_distances[np.triu_indices(num_data, 1)] = upper_tri_pdists\n",
    "    # Make symmetrical.\n",
    "    pairwise_distances = pairwise_distances + pairwise_distances.T - np.diag(\n",
    "        pairwise_distances.diagonal())\n",
    "    return pairwise_distances\n",
    "\n",
    "def test_pairwise_distances():\n",
    "    \"\"\"Test the pairwise distances function.\"\"\"\n",
    "    num_data = 64\n",
    "    feat_dim = 6\n",
    "    np.random.seed(42)\n",
    "\n",
    "    embeddings = np.random.randn(num_data, feat_dim).astype(np.float32)\n",
    "    embeddings[1] = embeddings[0]  # to get distance 0\n",
    "\n",
    "    for squared in [True, False]:\n",
    "        res_np = pairwise_distance_np(embeddings, squared=squared)\n",
    "        res_pt = _pairwise_distances(torch.from_numpy(embeddings), squared=squared)\n",
    "        assert np.allclose(res_np, res_pt)\n",
    "\n",
    "def test_pairwise_distances_are_positive():\n",
    "    \"\"\"Test that the pairwise distances are always positive.\n",
    "    Use a tricky case where numerical errors are common.\n",
    "    \"\"\"\n",
    "    num_data = 64\n",
    "    feat_dim = 6\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Create embeddings very close to each other in [1.0 - 2e-7, 1.0 + 2e-7]\n",
    "    # This will encourage errors in the computation\n",
    "    embeddings = 1.0 + 2e-7 * np.random.randn(num_data, feat_dim).astype(np.float32)\n",
    "    embeddings[1] = embeddings[0]  # to get distance 0\n",
    "\n",
    "    for squared in [True, False]:\n",
    "        res_tf = _pairwise_distances(torch.from_numpy(embeddings), squared=squared)\n",
    "        assert res_tf[res_tf < 0].sum() == 0\n",
    "\n",
    "\n",
    "def test_triplet_mask():\n",
    "    \"\"\"Test function _get_triplet_mask.\"\"\"\n",
    "    num_data = 64\n",
    "    num_classes = 10\n",
    "    np.random.seed(42)\n",
    "\n",
    "    labels = np.random.randint(0, num_classes, size=(num_data)).astype(np.float32)\n",
    "\n",
    "    mask_np = np.zeros((num_data, num_data, num_data))\n",
    "    for i in range(num_data):\n",
    "        for j in range(num_data):\n",
    "            for k in range(num_data):\n",
    "                distinct = (i != j and i != k and j != k)\n",
    "                valid = (labels[i] == labels[j]) and (labels[i] != labels[k])\n",
    "                mask_np[i, j, k] = (distinct and valid)\n",
    "\n",
    "    mask_tf_val = _get_triplet_mask(torch.from_numpy(labels))\n",
    "    assert np.allclose(mask_np, mask_tf_val)\n",
    "\n",
    "def test_anchor_positive_triplet_mask():\n",
    "    \"\"\"Test function _get_anchor_positive_triplet_mask.\"\"\"\n",
    "    num_data = 64\n",
    "    num_classes = 10\n",
    "    np.random.seed(42)\n",
    "\n",
    "    labels = np.random.randint(0, num_classes, size=(num_data)).astype(np.float32)\n",
    "\n",
    "    mask_np = np.zeros((num_data, num_data))\n",
    "    for i in range(num_data):\n",
    "        for j in range(num_data):\n",
    "            distinct = (i != j)\n",
    "            valid = labels[i] == labels[j]\n",
    "            mask_np[i, j] = (distinct and valid)\n",
    "\n",
    "    mask_tf_val = _get_anchor_positive_triplet_mask(torch.from_numpy(labels))\n",
    "\n",
    "    assert np.allclose(mask_np, mask_tf_val)\n",
    "\n",
    "def test_anchor_negative_triplet_mask():\n",
    "    \"\"\"Test function _get_anchor_negative_triplet_mask.\"\"\"\n",
    "    num_data = 64\n",
    "    num_classes = 10\n",
    "    np.random.seed(42)\n",
    "\n",
    "    labels = np.random.randint(0, num_classes, size=(num_data)).astype(np.float32)\n",
    "\n",
    "    mask_np = np.zeros((num_data, num_data))\n",
    "    for i in range(num_data):\n",
    "        for k in range(num_data):\n",
    "            distinct = (i != k)\n",
    "            valid = (labels[i] != labels[k])\n",
    "            mask_np[i, k] = (distinct and valid)\n",
    "\n",
    "    mask_tf_val = _get_anchor_negative_triplet_mask(torch.from_numpy(labels))\n",
    "\n",
    "    assert np.allclose(mask_np, mask_tf_val)\n",
    "\n",
    "test_pairwise_distances()\n",
    "test_pairwise_distances_are_positive()\n",
    "test_triplet_mask()\n",
    "test_anchor_positive_triplet_mask()\n",
    "test_anchor_negative_triplet_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def batch_hard_triplet_loss(labels, embeddings, margin, squared=False):\n",
    "    \"\"\"Build the triplet loss over a batch of embeddings.\n",
    "\n",
    "    For each anchor, we get the hardest positive and hardest negative to form a triplet.\n",
    "\n",
    "    Args:\n",
    "        labels: labels of the batch, of size (batch_size,)\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        margin: margin for triplet loss\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        triplet_loss: scalar tensor containing the triplet loss\n",
    "    \"\"\"\n",
    "    # Get the pairwise distance matrix\n",
    "    pairwise_dist = _pairwise_distances(embeddings, squared=squared)\n",
    "\n",
    "    # For each anchor, get the hardest positive\n",
    "    # First, we need to get a mask for every valid positive (they should have same label)\n",
    "    mask_anchor_positive = _get_anchor_positive_triplet_mask(labels).float()\n",
    "\n",
    "    # We put to 0 any element where (a, p) is not valid (valid if a != p and label(a) == label(p))\n",
    "    anchor_positive_dist = mask_anchor_positive * pairwise_dist\n",
    "\n",
    "    # shape (batch_size, 1)\n",
    "    hardest_positive_dist, _ = anchor_positive_dist.max(1, keepdim=True)\n",
    "\n",
    "    # For each anchor, get the hardest negative\n",
    "    # First, we need to get a mask for every valid negative (they should have different labels)\n",
    "    mask_anchor_negative = _get_anchor_negative_triplet_mask(labels).float()\n",
    "\n",
    "    # We add the maximum value in each row to the invalid negatives (label(a) == label(n))\n",
    "    max_anchor_negative_dist, _ = pairwise_dist.max(1, keepdim=True)\n",
    "    anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (1.0 - mask_anchor_negative)\n",
    "\n",
    "    # shape (batch_size,)\n",
    "    hardest_negative_dist, _ = anchor_negative_dist.min(1, keepdim=True)\n",
    "\n",
    "    # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
    "    tl = hardest_positive_dist - hardest_negative_dist + margin\n",
    "    tl = F.relu(tl)\n",
    "    triplet_loss = tl.mean()\n",
    "\n",
    "    return triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def batch_all_triplet_loss(labels, embeddings, margin, squared=False):\n",
    "    \"\"\"Build the triplet loss over a batch of embeddings.\n",
    "\n",
    "    We generate all the valid triplets and average the loss over the positive ones.\n",
    "\n",
    "    Args:\n",
    "        labels: labels of the batch, of size (batch_size,)\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        margin: margin for triplet loss\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        triplet_loss: scalar tensor containing the triplet loss\n",
    "    \"\"\"\n",
    "    # Get the pairwise distance matrix\n",
    "    pairwise_dist = _pairwise_distances(embeddings, squared=squared)\n",
    "\n",
    "    anchor_positive_dist = pairwise_dist.unsqueeze(2)\n",
    "    anchor_negative_dist = pairwise_dist.unsqueeze(1)\n",
    "\n",
    "    # Compute a 3D tensor of size (batch_size, batch_size, batch_size)\n",
    "    # triplet_loss[i, j, k] will contain the triplet loss of anchor=i, positive=j, negative=k\n",
    "    # Uses broadcasting where the 1st argument has shape (batch_size, batch_size, 1)\n",
    "    # and the 2nd (batch_size, 1, batch_size)\n",
    "    triplet_loss = anchor_positive_dist - anchor_negative_dist + margin\n",
    "\n",
    "\n",
    "\n",
    "    # Put to zero the invalid triplets\n",
    "    # (where label(a) != label(p) or label(n) == label(a) or a == p)\n",
    "    mask = _get_triplet_mask(labels)\n",
    "    triplet_loss = mask.float() * triplet_loss\n",
    "\n",
    "    # Remove negative losses (i.e. the easy triplets)\n",
    "    triplet_loss = F.relu(triplet_loss)\n",
    "\n",
    "    # Count number of positive triplets (where triplet_loss > 0)\n",
    "    valid_triplets = triplet_loss[triplet_loss > 1e-16]\n",
    "    num_positive_triplets = valid_triplets.size(0)\n",
    "    num_valid_triplets = mask.sum()\n",
    "\n",
    "    fraction_positive_triplets = num_positive_triplets / (num_valid_triplets.float() + 1e-16)\n",
    "\n",
    "    # Get final mean triplet loss over the positive valid triplets\n",
    "    triplet_loss = triplet_loss.sum() / (num_positive_triplets + 1e-16)\n",
    "\n",
    "    return triplet_loss, fraction_positive_triplets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.7060) tensor(0.7155)\n",
      "tensor(0.3978) tensor(0.8276)\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "def test_simple_batch_all_triplet_loss():\n",
    "    \"\"\"Test the triplet loss with batch all triplet mining in a simple case.\n",
    "    There is just one class in this super simple edge case, and we want to make sure that\n",
    "    the loss is 0.\n",
    "    \"\"\"\n",
    "    num_data = 10\n",
    "    feat_dim = 6\n",
    "    margin = 0.2\n",
    "    num_classes = 1\n",
    "    np.random.seed(42)\n",
    "\n",
    "    embeddings = np.random.rand(num_data, feat_dim).astype(np.float32)\n",
    "    labels = np.random.randint(0, num_classes, size=(num_data)).astype(np.float32)\n",
    "    labels, embeddings = torch.from_numpy(labels), torch.from_numpy(embeddings)\n",
    "\n",
    "    for squared in [True, False]:\n",
    "        loss_np = 0.0\n",
    "\n",
    "        # Compute the loss in TF.\n",
    "        loss_tf_val, fraction_val = batch_all_triplet_loss(labels, embeddings, margin, squared=squared)\n",
    "        print(loss_tf_val, fraction_val)\n",
    "        assert np.allclose(loss_np, loss_tf_val)\n",
    "        assert np.allclose(fraction_val, 0.0)\n",
    "\n",
    "\n",
    "def test_batch_all_triplet_loss():\n",
    "    \"\"\"Test the triplet loss with batch all triplet mining\"\"\"\n",
    "    num_data = 10\n",
    "    feat_dim = 6\n",
    "    margin = 0.2\n",
    "    num_classes = 5\n",
    "    np.random.seed(42)\n",
    "\n",
    "    embeddings = np.random.rand(num_data, feat_dim).astype(np.float32)\n",
    "    labels = np.random.randint(0, num_classes, size=(num_data)).astype(np.float32)\n",
    "\n",
    "    for squared in [True, False]:\n",
    "        pdist_matrix = pairwise_distance_np(embeddings, squared=squared)\n",
    "\n",
    "        loss_np = 0.0\n",
    "        num_positives = 0.0\n",
    "        num_valid = 0.0\n",
    "        for i in range(num_data):\n",
    "            for j in range(num_data):\n",
    "                for k in range(num_data):\n",
    "                    distinct = (i != j and i != k and j != k)\n",
    "                    valid = (labels[i] == labels[j]) and (labels[i] != labels[k])\n",
    "                    if distinct and valid:\n",
    "                        num_valid += 1.0\n",
    "\n",
    "                        pos_distance = pdist_matrix[i][j]\n",
    "                        neg_distance = pdist_matrix[i][k]\n",
    "\n",
    "                        loss = np.maximum(0.0, pos_distance - neg_distance + margin)\n",
    "                        loss_np += loss\n",
    "\n",
    "                        num_positives += (loss > 0)\n",
    "\n",
    "        loss_np /= num_positives\n",
    "\n",
    "        # Compute the loss in TF.\n",
    "        loss_tf_val, fraction_val = batch_all_triplet_loss(torch.from_numpy(labels), torch.from_numpy(embeddings), margin, squared=squared)\n",
    "        print(loss_tf_val, fraction_val)\n",
    "        assert np.allclose(loss_np, loss_tf_val)\n",
    "        assert np.allclose(num_positives / num_valid, fraction_val)\n",
    "\n",
    "def test_batch_hard_triplet_loss():\n",
    "    \"\"\"Test the triplet loss with batch hard triplet mining\"\"\"\n",
    "    num_data = 50\n",
    "    feat_dim = 6\n",
    "    margin = 0.2\n",
    "    num_classes = 5\n",
    "    np.random.seed(42)\n",
    "\n",
    "    embeddings = np.random.rand(num_data, feat_dim).astype(np.float32)\n",
    "    labels = np.random.randint(0, num_classes, size=(num_data)).astype(np.float32)\n",
    "\n",
    "    for squared in [True, False]:\n",
    "        pdist_matrix = pairwise_distance_np(embeddings, squared=squared)\n",
    "\n",
    "        loss_np = 0.0\n",
    "        for i in range(num_data):\n",
    "            # Select the hardest positive\n",
    "            max_pos_dist = np.max(pdist_matrix[i][labels == labels[i]])\n",
    "\n",
    "            # Select the hardest negative\n",
    "            min_neg_dist = np.min(pdist_matrix[i][labels != labels[i]])\n",
    "\n",
    "            loss = np.maximum(0.0, max_pos_dist - min_neg_dist + margin)\n",
    "            loss_np += loss\n",
    "\n",
    "        loss_np /= num_data\n",
    "\n",
    "        # Compute the loss in TF.\n",
    "        loss_tf_val = batch_hard_triplet_loss(torch.from_numpy(labels), torch.from_numpy(embeddings), margin, squared=squared)\n",
    "        assert np.allclose(loss_np, loss_tf_val)\n",
    "\n",
    "test_simple_batch_all_triplet_loss()\n",
    "test_batch_all_triplet_loss()\n",
    "test_batch_hard_triplet_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
